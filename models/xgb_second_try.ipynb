{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "52a90bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "af2685b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"                Model Evaluation Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R-squared (R2 ): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "b1ba9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(input, y_pred, key='Validation', filename='../output/random_forest_improved_predictions.csv'):\n",
    "    output = input[['DATETIME', 'ENTITY_DESCRIPTION_SHORT']].copy()\n",
    "    output['y_pred'] = y_pred\n",
    "    output['KEY'] = [key] * len(y_pred)\n",
    "    output.to_csv(filename, index=False)\n",
    "    print(f\"Predictions saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "1d2f4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_route = '../data/waiting_times_train.csv'\n",
    "validation_route = '../data/waiting_times_X_test_val.csv'\n",
    "test_route = '../data/waiting_times_X_test_final.csv'\n",
    "weather_route = '../data/weather_data.csv'\n",
    "\n",
    "train_file = pd.read_csv(train_route)\n",
    "validation_file = pd.read_csv(validation_route)\n",
    "test_file = pd.read_csv(test_route)\n",
    "weather_file = pd.read_csv(weather_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "d1c03a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 DATETIME  ADJUST_CAPACITY  DOWNTIME  CURRENT_WAIT_TIME  \\\n",
      "5927  2018-10-01 12:15:00            224.5         0                 20   \n",
      "8149  2018-10-01 12:15:00            756.0         0                 10   \n",
      "12003 2018-10-01 12:15:00            153.0         0                 25   \n",
      "13978 2018-10-01 12:30:00            153.0         0                 25   \n",
      "23029 2018-10-01 12:30:00            224.5         0                 20   \n",
      "\n",
      "       TIME_TO_PARADE_1  TIME_TO_PARADE_2  TIME_TO_NIGHT_SHOW  \\\n",
      "5927              315.0              -5.0               465.0   \n",
      "8149              315.0              -5.0               465.0   \n",
      "12003             315.0              -5.0               465.0   \n",
      "13978             300.0             -20.0               450.0   \n",
      "23029             300.0             -20.0               450.0   \n",
      "\n",
      "       WAIT_TIME_IN_2H   temp  dew_point  ...  \\\n",
      "5927              20.0  13.01       5.43  ...   \n",
      "8149              10.0  13.01       5.43  ...   \n",
      "12003             25.0  13.01       5.43  ...   \n",
      "13978             25.0  13.25       5.41  ...   \n",
      "23029             20.0  13.25       5.41  ...   \n",
      "\n",
      "       ENTITY_DESCRIPTION_SHORT_Water Ride  year  month  day  hour  minute  \\\n",
      "5927                                     1  2018     10    1    12      15   \n",
      "8149                                     0  2018     10    1    12      15   \n",
      "12003                                    0  2018     10    1    12      15   \n",
      "13978                                    0  2018     10    1    12      30   \n",
      "23029                                    1  2018     10    1    12      30   \n",
      "\n",
      "       rain_1h__6  rain_1h__3  snow_1h__6  snow_1h__3  \n",
      "5927       0.1239      0.1226         0.0         0.0  \n",
      "8149       0.1239      0.1226         0.0         0.0  \n",
      "12003      0.1239      0.1226         0.0         0.0  \n",
      "13978      0.1252      0.1239         0.0         0.0  \n",
      "23029      0.1252      0.1239         0.0         0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_file.copy()\n",
    "X_train['DATETIME'] = pd.to_datetime(X_train['DATETIME'], errors='coerce')\n",
    "\n",
    "weather_file['DATETIME'] = pd.to_datetime(weather_file['DATETIME'], errors='coerce')\n",
    "weather_file = weather_file.fillna(0)\n",
    "\n",
    "X_train = pd.merge(X_train, weather_file, on='DATETIME', how='left')\n",
    "X_train = pd.get_dummies(X_train, columns=['ENTITY_DESCRIPTION_SHORT'], drop_first=True, dtype=int)\n",
    "X_train['year'] = X_train['DATETIME'].dt.year\n",
    "X_train['month'] = X_train['DATETIME'].dt.month\n",
    "X_train['day'] = X_train['DATETIME'].dt.day\n",
    "X_train['hour'] = X_train['DATETIME'].dt.hour\n",
    "X_train['minute'] = X_train['DATETIME'].dt.minute\n",
    "\n",
    "X_train['TIME_TO_PARADE_1'] = X_train['TIME_TO_PARADE_1'].fillna(250)\n",
    "X_train['TIME_TO_PARADE_2'] = X_train['TIME_TO_PARADE_2'].fillna(0)\n",
    "\n",
    "X_train = X_train.sort_values(by='DATETIME')\n",
    "X_train['rain_1h__6'] = X_train['rain_1h'].shift(-6)\n",
    "X_train['rain_1h__3'] = X_train['rain_1h'].shift(-3)\n",
    "\n",
    "X_train['snow_1h__6'] = X_train['snow_1h'].shift(-6)\n",
    "X_train['snow_1h__3'] = X_train['snow_1h'].shift(-3)\n",
    "\n",
    "print(X_train.head())\n",
    "\n",
    "# Fill NaNs by column\n",
    "for col in X_train.select_dtypes(include=['number']).columns:\n",
    "    # Compute mean and std of non-NaN values\n",
    "    mean = X_train[col].mean()\n",
    "    std = X_train[col].std()\n",
    "    \n",
    "    # Find number of NaNs\n",
    "    n_nan = X_train[col].isna().sum()\n",
    "    \n",
    "    # Generate random numbers for NaNs\n",
    "    random_values = np.random.normal(loc=mean, scale=std, size=n_nan)\n",
    "    \n",
    "    # Fill NaNs\n",
    "    X_train.loc[X_train[col].isna(), col] = random_values\n",
    "\n",
    "X_train = X_train.sort_index()\n",
    "y_train = X_train['WAIT_TIME_IN_2H']\n",
    "X_train = X_train.select_dtypes(include=['number']).drop(columns=['WAIT_TIME_IN_2H','clouds_all', 'humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "81957a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.660283105824372 0.12363348343254574\n",
      "                Model Evaluation Metrics:\n",
      "Mean Absolute Error (MAE): 4.972195285533445\n",
      "Root Mean Squared Error (RMSE): 6.608539742824717\n",
      "R-squared (R2 ): 0.7858931369116848\n"
     ]
    }
   ],
   "source": [
    "optimized_estimators = 1900\n",
    "'''max_score = float('-inf')\n",
    "for n in range(100, 5000, 100):\n",
    "    model = XGBRegressor(n_estimators=n, learning_rate=0.1)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "    score_mean = scores.mean()\n",
    "    print(f\"n_estimators: {n}, CV Mean RMSE: {-score_mean}\")\n",
    "    if score_mean > max_score:\n",
    "        optimized_estimators = n\n",
    "        max_score = score_mean'''\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor(n_estimators=optimized_estimators, learning_rate=0.009, random_state=10)\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(scores.mean(), scores.std())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "evaluate_model(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "445a5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = validation_file.copy()\n",
    "X_val['DATETIME'] = pd.to_datetime(X_val['DATETIME'], errors='coerce')\n",
    "\n",
    "X_val = pd.merge(X_val, weather_file, on='DATETIME', how='left')\n",
    "X_val = pd.get_dummies(X_val, columns=['ENTITY_DESCRIPTION_SHORT'], drop_first=True, dtype=int)\n",
    "X_val['year'] = X_val['DATETIME'].dt.year\n",
    "X_val['month'] = X_val['DATETIME'].dt.month\n",
    "X_val['day'] = X_val['DATETIME'].dt.day\n",
    "X_val['hour'] = X_val['DATETIME'].dt.hour\n",
    "X_val['minute'] = X_val['DATETIME'].dt.minute\n",
    "\n",
    "X_val['TIME_TO_PARADE_1'] = X_val['TIME_TO_PARADE_1'].fillna(250)\n",
    "X_val['TIME_TO_PARADE_2'] = X_val['TIME_TO_PARADE_2'].fillna(0)\n",
    "\n",
    "X_val = X_val.sort_values(by='DATETIME')\n",
    "X_val['rain_1h__6'] = X_val['rain_1h'].shift(-6)\n",
    "X_val['rain_1h__3'] = X_val['rain_1h'].shift(-3)\n",
    "\n",
    "X_val['snow_1h__6'] = X_val['snow_1h'].shift(-6)\n",
    "X_val['snow_1h__3'] = X_val['snow_1h'].shift(-3)\n",
    "\n",
    "# Fill NaNs by column\n",
    "for col in X_val.select_dtypes(include=['number']).columns:\n",
    "    # Compute mean and std of non-NaN values\n",
    "    mean = X_val[col].mean()\n",
    "    std = X_val[col].std()\n",
    "    \n",
    "    # Find number of NaNs\n",
    "    n_nan = X_val[col].isna().sum()\n",
    "    \n",
    "    # Generate random numbers for NaNs\n",
    "    random_values = np.random.normal(loc=mean, scale=std, size=n_nan)\n",
    "    \n",
    "    # Fill NaNs\n",
    "    X_val.loc[X_val[col].isna(), col] = random_values\n",
    "\n",
    "X_val = X_val.sort_index()\n",
    "X_val = X_val.select_dtypes(include=['number']).drop(columns=['clouds_all','humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "7f755251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ../output/random_forest_improved_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = model.predict(X_val)\n",
    "generate_csv(validation_file, y_pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
